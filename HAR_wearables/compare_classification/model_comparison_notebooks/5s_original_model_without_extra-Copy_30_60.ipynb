{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e64c37ad-06e8-4134-bb77-544eb138bc05",
   "metadata": {},
   "source": [
    "- Generate epoch files with epoch length as 10 seconds.\n",
    "- Load the epoch files and label files with 10 second worth of labels.\n",
    "- Train the model.\n",
    "- Use the model to make predictions on test set and compare with actual annotations we have.\n",
    "- Make the confusion matrix.\n",
    "- Do it for: original model and custom features model.\n",
    "- Use those models for 22 random participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b341aaf-39f0-4571-a666-0273aafe023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(data_path) -> None:\n",
    "    total_csv_zipped = []\n",
    "    for path, dirnames, filenames in os.walk(data_path):\n",
    "        for file in filenames:\n",
    "            if file.endswith(\".csv.gz\"):\n",
    "                total_csv_zipped.append(os.path.join(path, file))\n",
    "                \n",
    "            if file.endswith(\".csv\") and file[0]!='c': #ignore the capture24 file\n",
    "                # paths contains the base directory for that file.\n",
    "                # dirnames contains other directories within this folder.\n",
    "                # filenames contains the list of filenames within path.\n",
    "                total_csv_zipped.append(os.path.join(path, file))\n",
    "    return sorted(total_csv_zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0e643ae-e494-40f2-9f63-339ba117b3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "epoch_size = 5 # 5 seconds\n",
    "\n",
    "epochs = \"/home/aayush/accelerometer/compare_classification/epoch_data/5_sec/original_features\"\n",
    "epoch_files = get_files(epochs)\n",
    "\n",
    "labels = \"/home/yacine/accel/capture24/participants/\"\n",
    "label_files = get_files(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8635f7ad-6ebe-40c8-bb9e-1100befdb373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def create_labels_dict(labels_dict_location = \"/home/aayush/accelerometer/accprocess/anno-label.csv\"):\n",
    "    labels_dict = {}\n",
    "    with open(labels_dict_location, \"r\") as annotation_dict:\n",
    "        reader = csv.DictReader(annotation_dict)\n",
    "        for row in reader:\n",
    "            if labels_dict.get(row['annotation']) is None:\n",
    "                labels_dict[row['annotation']] = [row['label:Walmsley2020']]\n",
    "            else:\n",
    "                labels_dict[row['annotation']].append(row['label:Walmsley2020'])\n",
    "    return labels_dict\n",
    "\n",
    "labels_dict = create_labels_dict()\n",
    "\n",
    "# replace the annotated labels with the same format of strings as predicted labels using mapping from labels_dict\n",
    "flat_dict = {k: v[0] for k, v in labels_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a3c7b2e-23c8-4749-a903-dde54ae43ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_datetime(dt_string):\n",
    "    clean_datetime_str = dt_string.split('[')[0].strip()\n",
    "    dt_object = pd.to_datetime(clean_datetime_str)\n",
    "    return dt_object\n",
    "\n",
    "\n",
    "def parse_datetime_df_time(dt_string):\n",
    "    clean_datetime_str = dt_string.split('[')[0].strip()\n",
    "    clean_datetime_str = clean_datetime_str.split('+')[0].strip()\n",
    "    dt_object = pd.to_datetime(clean_datetime_str)\n",
    "    return dt_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbda6a50-6f63-4108-956f-9e63cd1dca69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aayush/people_mobility_origin_dest/.accelerometer-original/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3577: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/151 done...\n",
      "2/151 done...\n",
      "3/151 done...\n",
      "4/151 done...\n",
      "5/151 done...\n",
      "6/151 done...\n",
      "7/151 done...\n",
      "8/151 done...\n",
      "9/151 done...\n",
      "10/151 done...\n",
      "11/151 done...\n",
      "12/151 done...\n",
      "13/151 done...\n",
      "14/151 done...\n",
      "15/151 done...\n",
      "16/151 done...\n",
      "17/151 done...\n",
      "18/151 done...\n",
      "19/151 done...\n",
      "20/151 done...\n",
      "21/151 done...\n",
      "22/151 done...\n",
      "23/151 done...\n",
      "24/151 done...\n",
      "25/151 done...\n",
      "26/151 done...\n",
      "27/151 done...\n",
      "28/151 done...\n",
      "29/151 done...\n",
      "30/151 done...\n"
     ]
    }
   ],
   "source": [
    "all_epoch_dfs = []\n",
    "for i, (epochfilename, labelfilename) in enumerate(zip(epoch_files[30:60], label_files[30:60])):\n",
    "    epoch_df = pd.read_csv(epochfilename)\n",
    "    label_df = pd.read_csv(labelfilename)\n",
    "\n",
    "    # Take the timestamp after every thirty seconds\n",
    "    label_df = label_df[[\"annotation\", \"time\"]][0::epoch_size]\n",
    "    \n",
    "    # Convert to datetime object\n",
    "    label_df[\"time\"] = label_df[\"time\"].apply(parse_datetime)\n",
    "\n",
    "    # replace the label with the categories we expect\n",
    "    label_df['annotation'] = label_df['annotation'].replace(flat_dict)\n",
    "\n",
    "    # convert epoch df time stamp with datetime object\n",
    "    epoch_df['time'] = epoch_df['time'].apply(parse_datetime_df_time)\n",
    "    epoch_df[\"participant\"] = float(epochfilename.split(\"/\")[-1].split(\"-\")[0][1:])\n",
    "\n",
    "    # predropped_epoch = len(epoch_df)\n",
    "    # predropped_label = len(label_df)\n",
    "    \n",
    "    # # keep only those time stamps which are present in both epoch and label df\n",
    "    # label_df = label_df[label_df[\"time\"].isin(epoch_df['time'])]\n",
    "    # epoch_df = epoch_df[epoch_df[\"time\"].isin(label_df['time'])]\n",
    "\n",
    "    # print(f\"We removed {predropped_label-len(label_df)} rows from label df because timestamps were not in epoch df.\")\n",
    "    # print(f\"We removed {predropped_epoch-len(epoch_df)} rows from epoch_df because timestamps were not in label_df.\")\n",
    "    \n",
    "    label_df = label_df[[\"time\", \"annotation\"]]\n",
    "    label_df.set_index(\"time\", inplace=True)\n",
    "    epoch_df.set_index(\"time\", inplace=True)\n",
    "    \n",
    "    # epoch_df[\"label\"] = label_df['annotation']\n",
    "    epoch_df=epoch_df.join(label_df, on=\"time\")\n",
    "    \n",
    "    all_epoch_dfs.append(epoch_df)\n",
    "    print(f\"{i+1}/{len(epoch_files)} done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0bd7543-393b-47c3-8c50-8d299b359931",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = pd.concat(all_epoch_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84ffae7a-a5e5-436e-b1a6-f46b7fe7da61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enmoTrunc</th>\n",
       "      <th>enmoAbs</th>\n",
       "      <th>xMean</th>\n",
       "      <th>yMean</th>\n",
       "      <th>zMean</th>\n",
       "      <th>xRange</th>\n",
       "      <th>yRange</th>\n",
       "      <th>zRange</th>\n",
       "      <th>xStd</th>\n",
       "      <th>yStd</th>\n",
       "      <th>...</th>\n",
       "      <th>p625</th>\n",
       "      <th>totalPower</th>\n",
       "      <th>temp</th>\n",
       "      <th>samples</th>\n",
       "      <th>dataErrors</th>\n",
       "      <th>clipsBeforeCalibr</th>\n",
       "      <th>clipsAfterCalibr</th>\n",
       "      <th>rawSamples</th>\n",
       "      <th>participant</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-30 00:53:00</th>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>-0.663161</td>\n",
       "      <td>0.695350</td>\n",
       "      <td>0.275062</td>\n",
       "      <td>0.015426</td>\n",
       "      <td>0.015587</td>\n",
       "      <td>0.015899</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.005566</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.287757</td>\n",
       "      <td>-14.224600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>501</td>\n",
       "      <td>31.0</td>\n",
       "      <td>sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30 00:53:05</th>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>-0.662945</td>\n",
       "      <td>0.696223</td>\n",
       "      <td>0.273854</td>\n",
       "      <td>0.015426</td>\n",
       "      <td>0.015587</td>\n",
       "      <td>0.015899</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.006304</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.169523</td>\n",
       "      <td>-14.317169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>502</td>\n",
       "      <td>31.0</td>\n",
       "      <td>sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30 00:53:10</th>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.002885</td>\n",
       "      <td>-0.663099</td>\n",
       "      <td>0.696628</td>\n",
       "      <td>0.271819</td>\n",
       "      <td>0.015426</td>\n",
       "      <td>0.015587</td>\n",
       "      <td>0.015899</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>0.006580</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.009971</td>\n",
       "      <td>-13.911440</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>502</td>\n",
       "      <td>31.0</td>\n",
       "      <td>sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30 00:53:15</th>\n",
       "      <td>0.001231</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>-0.663130</td>\n",
       "      <td>0.696129</td>\n",
       "      <td>0.274331</td>\n",
       "      <td>0.015426</td>\n",
       "      <td>0.015587</td>\n",
       "      <td>0.015899</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>0.006235</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.485773</td>\n",
       "      <td>-14.258189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>502</td>\n",
       "      <td>31.0</td>\n",
       "      <td>sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30 00:53:20</th>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>-0.663142</td>\n",
       "      <td>0.695524</td>\n",
       "      <td>0.274797</td>\n",
       "      <td>0.015597</td>\n",
       "      <td>0.015641</td>\n",
       "      <td>0.016498</td>\n",
       "      <td>0.001935</td>\n",
       "      <td>0.005744</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.263014</td>\n",
       "      <td>-14.378538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>502</td>\n",
       "      <td>31.0</td>\n",
       "      <td>sleep</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     enmoTrunc   enmoAbs     xMean     yMean     zMean  \\\n",
       "time                                                                     \n",
       "2016-03-30 00:53:00   0.001020  0.002526 -0.663161  0.695350  0.275062   \n",
       "2016-03-30 00:53:05   0.001086  0.002506 -0.662945  0.696223  0.273854   \n",
       "2016-03-30 00:53:10   0.001161  0.002885 -0.663099  0.696628  0.271819   \n",
       "2016-03-30 00:53:15   0.001231  0.002597 -0.663130  0.696129  0.274331   \n",
       "2016-03-30 00:53:20   0.001138  0.002736 -0.663142  0.695524  0.274797   \n",
       "\n",
       "                       xRange    yRange    zRange      xStd      yStd  ...  \\\n",
       "time                                                                   ...   \n",
       "2016-03-30 00:53:00  0.015426  0.015587  0.015899  0.002160  0.005566  ...   \n",
       "2016-03-30 00:53:05  0.015426  0.015587  0.015899  0.001192  0.006304  ...   \n",
       "2016-03-30 00:53:10  0.015426  0.015587  0.015899  0.001936  0.006580  ...   \n",
       "2016-03-30 00:53:15  0.015426  0.015587  0.015899  0.002051  0.006235  ...   \n",
       "2016-03-30 00:53:20  0.015597  0.015641  0.016498  0.001935  0.005744  ...   \n",
       "\n",
       "                          p625  totalPower  temp  samples  dataErrors  \\\n",
       "time                                                                    \n",
       "2016-03-30 00:53:00 -17.287757  -14.224600   0.0      500           0   \n",
       "2016-03-30 00:53:05 -17.169523  -14.317169   0.0      500           0   \n",
       "2016-03-30 00:53:10 -17.009971  -13.911440   0.0      500           0   \n",
       "2016-03-30 00:53:15 -17.485773  -14.258189   0.0      500           0   \n",
       "2016-03-30 00:53:20 -17.263014  -14.378538   0.0      500           0   \n",
       "\n",
       "                     clipsBeforeCalibr  clipsAfterCalibr  rawSamples  \\\n",
       "time                                                                   \n",
       "2016-03-30 00:53:00                  0                 0         501   \n",
       "2016-03-30 00:53:05                  0                 0         502   \n",
       "2016-03-30 00:53:10                  0                 0         502   \n",
       "2016-03-30 00:53:15                  0                 0         502   \n",
       "2016-03-30 00:53:20                  0                 0         502   \n",
       "\n",
       "                     participant  annotation  \n",
       "time                                          \n",
       "2016-03-30 00:53:00         31.0       sleep  \n",
       "2016-03-30 00:53:05         31.0       sleep  \n",
       "2016-03-30 00:53:10         31.0       sleep  \n",
       "2016-03-30 00:53:15         31.0       sleep  \n",
       "2016-03-30 00:53:20         31.0       sleep  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = epochs\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c630412-ad4b-4a88-abe0-eee677ed6ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556084\n"
     ]
    }
   ],
   "source": [
    "df.rename(columns={'annotation':'label'}, inplace=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d37f111a-8cc4-44cf-b2e6-e682fd9abd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sleep' nan 'light' 'sedentary' 'moderate-vigorous']\n"
     ]
    }
   ],
   "source": [
    "print(df['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1050a1cd-82bd-4e49-bf1b-e2c81fa9b6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(labels=[\"time\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "115dbbc2-92a6-4209-8c4c-b8f7c7791daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sleep' 'light' 'sedentary' 'moderate-vigorous']\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=[\"label\"])\n",
    "print(df['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15c42d12-7d04-43dc-9521-44d71035d866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352540"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[\"label\"] = df[\"label\"].astype('string', copy=False)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d8e6b3b-9f8d-4545-90bd-7f45e710eabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/home/aayush/accelerometer/compare_classification/training_data/5_sec/original_features/5s_training_original_features_30_60.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c87096-ceda-4f98-b04b-192a8b124037",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_participants = \"101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151\"\n",
    "test_participants = [float(t) for t in test_participants.split(\",\")]\n",
    "    \n",
    "test_features_df = df[df[\"participant\"].isin(test_participants)].iloc[:, :-2]\n",
    "test_labels_df = df[df[\"participant\"].isin(test_participants)][\"label\"]\n",
    "\n",
    "print(len(test_features_df))\n",
    "print(test_labels_df.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a8c635-3eef-4bd2-9b78-326fbc5cd19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_df = df[~df[\"participant\"].isin(test_participants)]\n",
    "train_features_df = df[~df[\"participant\"].isin(test_participants)].iloc[:, :-2]\n",
    "train_labels_predict = df[~df[\"participant\"].isin(test_participants)][\"label\"]\n",
    "\n",
    "print(len(train_features_df))\n",
    "print(train_labels_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a087d5-a46a-4a7a-b371-8399e68020b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _Model(**kwargs):\n",
    "    return BalancedRandomForestClassifier(\n",
    "        n_estimators=3000,\n",
    "        max_depth=10,\n",
    "        min_samples_leaf=1,\n",
    "        replacement=True,\n",
    "        sampling_strategy='not minority',\n",
    "        random_state=42,\n",
    "        **kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d57b44-78bb-4065-8938-461236c046d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "print('Training...')\n",
    "model = _Model(n_jobs=10, verbose=1)\n",
    "# fit the model as numpy array so that we do not get warnings during prediction\n",
    "X_features = train_features_df.to_numpy()\n",
    "X_labels = train_labels_predict.to_numpy()\n",
    "model = model.fit(X_features, X_labels)\n",
    "model.verbose = 0  # silence future calls to .predict()\n",
    "labels = model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2871c93-f583-41dc-99e1-d8c9237f62ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels)\n",
    "pid = df[~df[\"participant\"].isin(test_participants)][\"participant\"].to_numpy()\n",
    "print(len(pid))\n",
    "print(len(train_labels_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bbd643-5918-43e2-ad80-55f5c1abd0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveToTar(tarOut, **kwargs):\n",
    "    \"\"\"Save objects to tar file. Objects must be passed as keyworded arguments,\n",
    "    then the key is used for the object name in the tar file.\n",
    "\n",
    "    :param **kwargs: Objects to be saved passed as keyworded arguments.\n",
    "\n",
    "    :return: tar file written to <tarOut>\n",
    "    :rtype: void\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "\n",
    "        tmpdir = tempfile.mkdtemp()\n",
    "\n",
    "        with tarfile.open(tarOut, mode='w') as tf:\n",
    "\n",
    "            for key, val in kwargs.items():\n",
    "                pth = os.path.join(tmpdir, key)\n",
    "                joblib.dump(val, pth, compress=True)\n",
    "                tf.add(pth, arcname=key)\n",
    "\n",
    "        print('Models saved to', tarOut)\n",
    "\n",
    "    finally:\n",
    "\n",
    "        try:\n",
    "            shutil.rmtree(tmpdir)\n",
    "        except OSError as e:\n",
    "            print(\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
    "\n",
    "\n",
    "def getFileFromTar(tarArchive, targetFile):\n",
    "    \"\"\"Read file from tar\n",
    "\n",
    "    This is currently more tricky than it should be see\n",
    "    https://github.com/numpy/numpy/issues/7989\n",
    "\n",
    "    :param str tarArchive: Input tarfile object\n",
    "    :param str targetFile: Target individual file within .tar\n",
    "\n",
    "    :return: file object byte stream\n",
    "    :rtype: object\n",
    "    \"\"\"\n",
    "\n",
    "    with tarfile.open(tarArchive, 'r') as t:\n",
    "        b = BytesIO()\n",
    "        try:\n",
    "            b.write(t.extractfile(targetFile).read())\n",
    "        except KeyError:\n",
    "            return None\n",
    "        b.seek(0)\n",
    "\n",
    "    return b\n",
    "\n",
    "\n",
    "def trainHMM(Y_prob, Y_true, labels=None, uniform_prior=True):\n",
    "    \"\"\" https://en.wikipedia.org/wiki/Hidden_Markov_model\n",
    "\n",
    "    :return: Dictionary containing prior, emission and transition\n",
    "        matrices, and corresponding labels.\n",
    "    :rtype: dict\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if labels is None:\n",
    "        labels = np.unique(Y_true)\n",
    "\n",
    "    if uniform_prior:\n",
    "        # All labels with equal probability\n",
    "        prior = np.ones(len(labels)) / len(labels)\n",
    "    else:\n",
    "        # Label probability equals empirical rate\n",
    "        prior = np.mean(Y_true.reshape(-1, 1) == labels, axis=0)\n",
    "\n",
    "    emission = np.vstack(\n",
    "        [np.mean(Y_prob[Y_true == label], axis=0) for label in labels]\n",
    "    )\n",
    "    transition = np.vstack(\n",
    "        [np.mean(Y_true[1:][(Y_true == label)[:-1]].reshape(-1, 1) == labels, axis=0)\n",
    "            for label in labels]\n",
    "    )\n",
    "\n",
    "    params = {'prior': prior, 'emission': emission, 'transition': transition, 'labels': labels}\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b97bf4c-9a3b-474f-a55e-43e9b8cf6f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "print('Cross-predicting to derive the observations for HMM...')\n",
    "\n",
    "NJOBS_PER_CV_MODEL = min(2, 10)\n",
    "cvp = cross_val_predict(\n",
    "    _Model(n_jobs=NJOBS_PER_CV_MODEL), X_features, X_labels, groups=pid,\n",
    "    cv=10,\n",
    "    n_jobs=10 // NJOBS_PER_CV_MODEL,\n",
    "    method=\"predict_proba\",\n",
    "    verbose=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9580ae-7fc6-4e32-a823-c1148e0bce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c601f0f-4620-48c8-a199-5cbcb8dee04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training HMM...')\n",
    "# train_labels_predict_array = np.array(train_labels_predict)\n",
    "# hmmParams = trainHMM(cvp,  train_labels_predict_array)\n",
    "\n",
    "hmmParams = trainHMM(cvp,  X_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032fcb6d-744c-48f2-a742-66dc7c4c454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmmParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aa86d6-1861-4ba8-affa-7b4c65aee5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METs = {y: train_all_df[train_all_df[\"label\"] == y].groupby(\"label\")[\"MET\"].mean().mean() \n",
    "#     for y in model.classes_}\n",
    "METs = {'light': 2.270833333333333,\n",
    " 'moderate-vigorous': 4.682608695652173,\n",
    " 'sedentary': 1.5634920634920637,\n",
    " 'sleep': 0.9499999999999998}\n",
    "METs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21fc588-9178-4c90-ac79-755710da3db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "import joblib\n",
    "import tarfile\n",
    "\n",
    "featureCols = np.array(train_features_df.columns)\n",
    "# Write model to file\n",
    "outFile = os.path.join(\"/home/aayush/accelerometer/compare_classification/accProcess_output/5_sec/original_features/model_used\", '5s_without_extra_model.tar')\n",
    "saveToTar(outFile,\n",
    "          model=model,\n",
    "          labels=labels,\n",
    "          featureCols=featureCols,\n",
    "          hmmParams=hmmParams,\n",
    "          METs=METs)\n",
    "print(f'Output trained model written to: {outFile}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8995be60-3bec-4094-822d-e666732d780f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display feature importances\n",
    "feature_importances = pd.Series(model.feature_importances_, index=df.columns[:-2])\n",
    "print(feature_importances.nlargest(30))  # Show the top 30 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c382ec-c3e6-4413-849c-c471a950a39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "# test the performance\n",
    "Y_labels_test_pred = model.predict(test_features_df)\n",
    "print(metrics.classification_report(test_labels_df, Y_labels_test_pred))\n",
    "testScore = metrics.f1_score(test_labels_df, Y_labels_test_pred, average='macro', zero_division=0)\n",
    "print(f'Score: {testScore:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f50971-8d52-44f4-bcae-2ef53af914cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(Y_obs, hmm_params):\n",
    "    \"\"\" Perform HMM smoothing over observations via Viteri algorithm\n",
    "\n",
    "    https://en.wikipedia.org/wiki/Viterbi_algorithm\n",
    "\n",
    "    :param dict hmm_params: Dictionary containing prior, emission and transition\n",
    "        matrices, and corresponding labels\n",
    "\n",
    "    :return: Smoothed sequence of activities\n",
    "    :rtype: numpy.array\n",
    "    \"\"\"\n",
    "\n",
    "    def log(x):\n",
    "        SMALL_NUMBER = 1e-16\n",
    "        return np.log(x + SMALL_NUMBER)\n",
    "\n",
    "    prior = hmm_params['prior']\n",
    "    emission = hmm_params['emission']\n",
    "    transition = hmm_params['transition']\n",
    "    labels = hmm_params['labels']\n",
    "\n",
    "    nobs = len(Y_obs)\n",
    "    nlabels = len(labels)\n",
    "\n",
    "    Y_obs = np.where(Y_obs.reshape(-1, 1) == labels)[1]  # to numeric\n",
    "\n",
    "    probs = np.zeros((nobs, nlabels))\n",
    "    probs[0, :] = log(prior) + log(emission[:, Y_obs[0]])\n",
    "    for j in range(1, nobs):\n",
    "        for i in range(nlabels):\n",
    "            probs[j, i] = np.max(\n",
    "                log(emission[i, Y_obs[j]]) +\n",
    "                log(transition[:, i]) +\n",
    "                probs[j - 1, :])  # probs already in log scale\n",
    "    viterbi_path = np.zeros_like(Y_obs)\n",
    "    viterbi_path[-1] = np.argmax(probs[-1, :])\n",
    "    for j in reversed(range(nobs - 1)):\n",
    "        viterbi_path[j] = np.argmax(\n",
    "            log(transition[:, viterbi_path[j + 1]]) +\n",
    "            probs[j, :])  # probs already in log scale\n",
    "\n",
    "    viterbi_path = labels[viterbi_path]  # to labels\n",
    "\n",
    "    return viterbi_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a4ab6f-4cac-4df9-bfdb-84afcc1b9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "YpredHmm = viterbi(Y_labels_test_pred, hmmParams)\n",
    "\n",
    "print('\\nTest performance (HMM):')\n",
    "print(metrics.classification_report(test_labels_df, YpredHmm))\n",
    "testHmmScore = metrics.f1_score(test_labels_df, YpredHmm, average='macro', zero_division=0)\n",
    "print(f'Score: {testHmmScore:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a98d5ed-f517-4e6e-9d9b-ce9c0110aa16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".accelerometer-original",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
